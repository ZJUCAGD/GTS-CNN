{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-tda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from ripser import Rips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute PD of PC\n",
    "\n",
    "**WARNING!** It takes several hours to compute PDs so we provide PDs directly in `PD_pc` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rips = Rips()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.load('./shapenet_test_18nn_GM_adaptive_knn_sparse.npy', allow_pickle=True)\n",
    "test_label = test_data.tolist()['label']\n",
    "test_data = test_data.tolist()['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if not os.path.exists('PD_shapenet_test'):\n",
    "    os.mkdir('PD_shapenet_test')\n",
    "\n",
    "for i in tqdm_notebook(range(len(test_data))):\n",
    "    data = test_data[i]\n",
    "\n",
    "    dgm = rips.fit_transform(data)\n",
    "    #np.savetxt('./PD_shapenet_test/0_' + str(i) + '.txt', np.array(dgm[0]), fmt='%s')\n",
    "    np.savetxt('./PD_shapenet_test/1_' + str(i) + '.txt', np.array(dgm[1]), fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load('./shapenet_train_18nn_GM_adaptive_knn_sparse.npy', allow_pickle=True)\n",
    "train_label = train_data.tolist()['label']\n",
    "train_data = train_data.tolist()['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob('PD_shapenet_train/1_*')\n",
    "files = sorted(files, key=lambda x: int(x.split('/')[-1].split('.')[0].split('_')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "723970b8aebb4a19bc398b1a60bfff89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1224), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#idx = []\n",
    "for i in tqdm_notebook(idx):\n",
    "#    file = 'PD_shapenet_train/1_' + str(i) + '.txt'\n",
    "#     if file not in files:\n",
    "#         idx.append(i)\n",
    "#         print(file)\n",
    "    \n",
    "    data = train_data[i]\n",
    "    \n",
    "    dgm = rips.fit_transform(data)\n",
    "    np.savetxt('./PD_shapenet_train/0_' + str(i) + '.txt', np.array(dgm[0]), fmt='%s')\n",
    "    np.savetxt('./PD_shapenet_train/1_' + str(i) + '.txt', np.array(dgm[1]), fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if not os.path.exists('PD_shapenet_train'):\n",
    "    os.mkdir('PD_shapenet_train')\n",
    "\n",
    "for i in tqdm_notebook(range(len(train_data))):\n",
    "    data = train_data[i]\n",
    "    dgm = rips.fit_transform(data)\n",
    "    np.savetxt('./PD_shapenet_train/0_' + str(i) + '.txt', np.array(dgm[0]), fmt='%s')\n",
    "    np.savetxt('./PD_shapenet_train/1_' + str(i) + '.txt', np.array(dgm[1]), fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(i):\n",
    "    data = test_data[i]\n",
    "    dgm = rips.fit_transform(data)\n",
    "    #np.savetxt('./PD_shapenet_test/0_' + str(i) + '.txt', np.array(dgm[0]), fmt='%s')\n",
    "    np.savetxt('./PD_shapenet_test/1_' + str(i) + '.txt', np.array(dgm[1]), fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all cores\n",
    "cores = 8 #multiprocessing.cpu_count()\n",
    "# start a pool\n",
    "pool = multiprocessing.Pool(processes=cores)\n",
    "tasks = list(range(len(test_data)))\n",
    "# do parallel calculate\n",
    "print(pool.map(f, tasks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization\n",
    "pd_files = glob.glob('./PD_pc/*.txt')\n",
    "pd_files = sorted(pd_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H0 normalization\n",
    "max_h0 = 0\n",
    "for i in range(len(pd_files)//2):\n",
    "    data = np.loadtxt(pd_files[i])[:-1]  # disgarding inf \n",
    "    if np.max(data) > max_h0:\n",
    "        max_h0 = np.max(data)\n",
    "\n",
    "# H1 normalization\n",
    "max_h1 = 0\n",
    "for i in range(len(pd_files)//2):\n",
    "    data = np.loadtxt(pd_files[len(pd_files)//2 + i])\n",
    "    try:\n",
    "        data[:, 1] = data[:, 1] - data[:, 0]\n",
    "    except:\n",
    "        data = data.reshape((1, 2))\n",
    "        data[:, 1] = data[:, 1] - data[:, 0]\n",
    "    if np.max(data) > max_h1:\n",
    "        max_h1 = np.max(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7010728120803833, 1.0598217248916626)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_h0, max_h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H0 normalization\n",
    "for i in range(len(pd_files)//2):\n",
    "    data = np.loadtxt(pd_files[i])[:-1]  # disgarding inf     \n",
    "    data = data / max_h0\n",
    "    np.savetxt('./PD_pc/' + pd_files[i].split('/')[-1], data, fmt='%s')\n",
    "\n",
    "# H1 normalization\n",
    "for i in range(len(pd_files)//2):\n",
    "    data = np.loadtxt(pd_files[len(pd_files)//2 + i]) \n",
    "    try:\n",
    "        data[:, 1] = data[:, 1] - data[:, 0]\n",
    "    except:\n",
    "        data = data.reshape((1, 2))\n",
    "        data[:, 1] = data[:, 1] - data[:, 0]\n",
    "    data = data / max_h1\n",
    "    np.savetxt('./PD_pc/' + pd_files[len(pd_files)//2 + i].split('/')[-1], data, fmt='%s')        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
